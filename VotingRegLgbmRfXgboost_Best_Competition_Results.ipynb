{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n","from sklearn.metrics import r2_score\n","from sklearn.preprocessing import LabelEncoder, PolynomialFeatures\n","from xgboost import XGBRegressor\n","import numpy as np\n","from sklearn.model_selection import KFold\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["df_train = pd.read_csv('./training_data.csv')\n","df_test = pd.read_csv('./testing_data.csv')"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>timestamp</th>\n","      <th>cpu_type</th>\n","      <th>cpu_limit</th>\n","      <th>ram_limit</th>\n","      <th>cpu_usage</th>\n","      <th>ram_usage</th>\n","      <th>num_req</th>\n","      <th>conc_lvl</th>\n","      <th>latency</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2714</td>\n","      <td>2021-11-04 23:15:38</td>\n","      <td>Intel Xeon Gold 5317</td>\n","      <td>2.0</td>\n","      <td>70M</td>\n","      <td>0.084450</td>\n","      <td>46854144.0</td>\n","      <td>100</td>\n","      <td>71</td>\n","      <td>7429000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>38113</td>\n","      <td>2021-11-04 23:23:27</td>\n","      <td>AMD EPYC 72F3</td>\n","      <td>2.0</td>\n","      <td>70M</td>\n","      <td>0.277893</td>\n","      <td>55934976.0</td>\n","      <td>300</td>\n","      <td>21</td>\n","      <td>2196000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>33409</td>\n","      <td>2021-11-11 13:32:59</td>\n","      <td>Intel Xeon Platinum 8380</td>\n","      <td>2.5</td>\n","      <td>66M</td>\n","      <td>0.351042</td>\n","      <td>59109376.0</td>\n","      <td>700</td>\n","      <td>1</td>\n","      <td>37000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10123</td>\n","      <td>2022-03-19 02:35:05</td>\n","      <td>Intel Xeon Platinum 8356H</td>\n","      <td>0.8</td>\n","      <td>768M</td>\n","      <td>0.026230</td>\n","      <td>43659264.0</td>\n","      <td>100</td>\n","      <td>41</td>\n","      <td>3946000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>12815</td>\n","      <td>2022-03-17 06:30:29</td>\n","      <td>AMD EPYC 72F3</td>\n","      <td>0.4</td>\n","      <td>512M</td>\n","      <td>0.108346</td>\n","      <td>51048448.0</td>\n","      <td>800</td>\n","      <td>51</td>\n","      <td>5084000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      ID            timestamp                   cpu_type  cpu_limit ram_limit  \\\n","0   2714  2021-11-04 23:15:38       Intel Xeon Gold 5317        2.0       70M   \n","1  38113  2021-11-04 23:23:27              AMD EPYC 72F3        2.0       70M   \n","2  33409  2021-11-11 13:32:59   Intel Xeon Platinum 8380        2.5       66M   \n","3  10123  2022-03-19 02:35:05  Intel Xeon Platinum 8356H        0.8      768M   \n","4  12815  2022-03-17 06:30:29              AMD EPYC 72F3        0.4      512M   \n","\n","   cpu_usage   ram_usage  num_req  conc_lvl  latency  \n","0   0.084450  46854144.0      100        71  7429000  \n","1   0.277893  55934976.0      300        21  2196000  \n","2   0.351042  59109376.0      700         1    37000  \n","3   0.026230  43659264.0      100        41  3946000  \n","4   0.108346  51048448.0      800        51  5084000  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df_train.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["Index(['ID', 'timestamp', 'cpu_type', 'cpu_limit', 'ram_limit', 'cpu_usage',\n","       'ram_usage', 'num_req', 'conc_lvl', 'latency'],\n","      dtype='object')"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df_train.columns"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 41134 entries, 0 to 41133\n","Data columns (total 10 columns):\n"," #   Column     Non-Null Count  Dtype  \n","---  ------     --------------  -----  \n"," 0   ID         41134 non-null  int64  \n"," 1   timestamp  41134 non-null  object \n"," 2   cpu_type   41134 non-null  object \n"," 3   cpu_limit  41134 non-null  float64\n"," 4   ram_limit  41134 non-null  object \n"," 5   cpu_usage  41134 non-null  float64\n"," 6   ram_usage  41134 non-null  float64\n"," 7   num_req    41134 non-null  int64  \n"," 8   conc_lvl   41134 non-null  int64  \n"," 9   latency    41134 non-null  int64  \n","dtypes: float64(3), int64(4), object(3)\n","memory usage: 3.1+ MB\n","None\n","                 ID     cpu_limit     cpu_usage     ram_usage       num_req  \\\n","count  41134.000000  41134.000000  41134.000000  4.113400e+04  41134.000000   \n","mean   29357.337434      1.445007      0.205489  5.377951e+07    532.958137   \n","std    16909.992230      1.077288      0.141493  7.771771e+06    286.221513   \n","min        0.000000      0.100000      0.000000  0.000000e+00    100.000000   \n","25%    14796.250000      0.500000      0.109756  4.941005e+07    300.000000   \n","50%    29311.500000      1.300000      0.167758  5.224448e+07    500.000000   \n","75%    43993.750000      2.000000      0.312084  5.872845e+07    800.000000   \n","max    58762.000000      4.000000      3.998097  1.371832e+08   1000.000000   \n","\n","           conc_lvl       latency  \n","count  41134.000000  4.113400e+04  \n","mean      37.228424  6.483698e+06  \n","std       27.515045  1.492553e+07  \n","min        1.000000  2.500000e+04  \n","25%       11.000000  1.175250e+06  \n","50%       31.000000  3.756000e+06  \n","75%       51.000000  6.022000e+06  \n","max      101.000000  2.667150e+08  \n"]}],"source":["print(df_train.info())\n","print(df_train.describe())"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["(41134, 10)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df_train.shape"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["df_train.dropna(inplace=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["df_train['timestamp'] = pd.to_datetime(df_train['timestamp'])\n","df_train['hour'] = df_train['timestamp'].dt.hour\n","df_train['dayofweek'] = df_train['timestamp'].dt.dayofweek"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["df_train['log_cpu_usage'] = np.log1p(df_train['cpu_usage'])\n","df_train['log_ram_usage'] = np.log1p(df_train['ram_usage'])\n","df_train['log_num_req'] = np.log1p(df_train['num_req'])\n","df_train['log_conc_lvl'] = np.log1p(df_train['conc_lvl'])"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>timestamp</th>\n","      <th>cpu_type</th>\n","      <th>cpu_limit</th>\n","      <th>ram_limit</th>\n","      <th>cpu_usage</th>\n","      <th>ram_usage</th>\n","      <th>num_req</th>\n","      <th>conc_lvl</th>\n","      <th>latency</th>\n","      <th>hour</th>\n","      <th>dayofweek</th>\n","      <th>log_cpu_usage</th>\n","      <th>log_ram_usage</th>\n","      <th>log_num_req</th>\n","      <th>log_conc_lvl</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2714</td>\n","      <td>2021-11-04 23:15:38</td>\n","      <td>Intel Xeon Gold 5317</td>\n","      <td>2.0</td>\n","      <td>70M</td>\n","      <td>0.084450</td>\n","      <td>46854144.0</td>\n","      <td>100</td>\n","      <td>71</td>\n","      <td>7429000</td>\n","      <td>23</td>\n","      <td>3</td>\n","      <td>0.081073</td>\n","      <td>17.662550</td>\n","      <td>4.615121</td>\n","      <td>4.276666</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>38113</td>\n","      <td>2021-11-04 23:23:27</td>\n","      <td>AMD EPYC 72F3</td>\n","      <td>2.0</td>\n","      <td>70M</td>\n","      <td>0.277893</td>\n","      <td>55934976.0</td>\n","      <td>300</td>\n","      <td>21</td>\n","      <td>2196000</td>\n","      <td>23</td>\n","      <td>3</td>\n","      <td>0.245213</td>\n","      <td>17.839700</td>\n","      <td>5.707110</td>\n","      <td>3.091042</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>33409</td>\n","      <td>2021-11-11 13:32:59</td>\n","      <td>Intel Xeon Platinum 8380</td>\n","      <td>2.5</td>\n","      <td>66M</td>\n","      <td>0.351042</td>\n","      <td>59109376.0</td>\n","      <td>700</td>\n","      <td>1</td>\n","      <td>37000</td>\n","      <td>13</td>\n","      <td>3</td>\n","      <td>0.300876</td>\n","      <td>17.894900</td>\n","      <td>6.552508</td>\n","      <td>0.693147</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10123</td>\n","      <td>2022-03-19 02:35:05</td>\n","      <td>Intel Xeon Platinum 8356H</td>\n","      <td>0.8</td>\n","      <td>768M</td>\n","      <td>0.026230</td>\n","      <td>43659264.0</td>\n","      <td>100</td>\n","      <td>41</td>\n","      <td>3946000</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>0.025892</td>\n","      <td>17.591926</td>\n","      <td>4.615121</td>\n","      <td>3.737670</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>12815</td>\n","      <td>2022-03-17 06:30:29</td>\n","      <td>AMD EPYC 72F3</td>\n","      <td>0.4</td>\n","      <td>512M</td>\n","      <td>0.108346</td>\n","      <td>51048448.0</td>\n","      <td>800</td>\n","      <td>51</td>\n","      <td>5084000</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>0.102869</td>\n","      <td>17.748286</td>\n","      <td>6.685861</td>\n","      <td>3.951244</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>41129</th>\n","      <td>54343</td>\n","      <td>2022-03-18 02:05:09</td>\n","      <td>Intel Xeon Silver 4309Y</td>\n","      <td>0.7</td>\n","      <td>896M</td>\n","      <td>0.169227</td>\n","      <td>50458624.0</td>\n","      <td>900</td>\n","      <td>11</td>\n","      <td>1039000</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>0.156343</td>\n","      <td>17.736664</td>\n","      <td>6.803505</td>\n","      <td>2.484907</td>\n","    </tr>\n","    <tr>\n","      <th>41130</th>\n","      <td>38158</td>\n","      <td>2022-03-11 14:24:38</td>\n","      <td>Intel Core i9-11900K</td>\n","      <td>1.5</td>\n","      <td>640M</td>\n","      <td>0.147585</td>\n","      <td>50913280.0</td>\n","      <td>300</td>\n","      <td>1</td>\n","      <td>53000</td>\n","      <td>14</td>\n","      <td>4</td>\n","      <td>0.137660</td>\n","      <td>17.745634</td>\n","      <td>5.707110</td>\n","      <td>0.693147</td>\n","    </tr>\n","    <tr>\n","      <th>41131</th>\n","      <td>860</td>\n","      <td>2022-03-16 16:28:38</td>\n","      <td>Intel Xeon Platinum 8352M</td>\n","      <td>1.8</td>\n","      <td>640M</td>\n","      <td>0.134895</td>\n","      <td>51859456.0</td>\n","      <td>900</td>\n","      <td>31</td>\n","      <td>3145000</td>\n","      <td>16</td>\n","      <td>2</td>\n","      <td>0.126540</td>\n","      <td>17.764048</td>\n","      <td>6.803505</td>\n","      <td>3.465736</td>\n","    </tr>\n","    <tr>\n","      <th>41132</th>\n","      <td>15795</td>\n","      <td>2022-03-17 03:18:29</td>\n","      <td>Intel Xeon Platinum 8368</td>\n","      <td>0.7</td>\n","      <td>768M</td>\n","      <td>0.203862</td>\n","      <td>45862912.0</td>\n","      <td>800</td>\n","      <td>21</td>\n","      <td>2001000</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0.185535</td>\n","      <td>17.641167</td>\n","      <td>6.685861</td>\n","      <td>3.091042</td>\n","    </tr>\n","    <tr>\n","      <th>41133</th>\n","      <td>56422</td>\n","      <td>2022-03-07 05:19:28</td>\n","      <td>Intel Xeon Platinum 8354H</td>\n","      <td>0.1</td>\n","      <td>1024M</td>\n","      <td>0.100398</td>\n","      <td>59518976.0</td>\n","      <td>900</td>\n","      <td>11</td>\n","      <td>5608000</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0.095672</td>\n","      <td>17.901806</td>\n","      <td>6.803505</td>\n","      <td>2.484907</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>41134 rows × 16 columns</p>\n","</div>"],"text/plain":["          ID           timestamp                   cpu_type  cpu_limit  \\\n","0       2714 2021-11-04 23:15:38       Intel Xeon Gold 5317        2.0   \n","1      38113 2021-11-04 23:23:27              AMD EPYC 72F3        2.0   \n","2      33409 2021-11-11 13:32:59   Intel Xeon Platinum 8380        2.5   \n","3      10123 2022-03-19 02:35:05  Intel Xeon Platinum 8356H        0.8   \n","4      12815 2022-03-17 06:30:29              AMD EPYC 72F3        0.4   \n","...      ...                 ...                        ...        ...   \n","41129  54343 2022-03-18 02:05:09    Intel Xeon Silver 4309Y        0.7   \n","41130  38158 2022-03-11 14:24:38       Intel Core i9-11900K        1.5   \n","41131    860 2022-03-16 16:28:38  Intel Xeon Platinum 8352M        1.8   \n","41132  15795 2022-03-17 03:18:29   Intel Xeon Platinum 8368        0.7   \n","41133  56422 2022-03-07 05:19:28  Intel Xeon Platinum 8354H        0.1   \n","\n","      ram_limit  cpu_usage   ram_usage  num_req  conc_lvl  latency  hour  \\\n","0           70M   0.084450  46854144.0      100        71  7429000    23   \n","1           70M   0.277893  55934976.0      300        21  2196000    23   \n","2           66M   0.351042  59109376.0      700         1    37000    13   \n","3          768M   0.026230  43659264.0      100        41  3946000     2   \n","4          512M   0.108346  51048448.0      800        51  5084000     6   \n","...         ...        ...         ...      ...       ...      ...   ...   \n","41129      896M   0.169227  50458624.0      900        11  1039000     2   \n","41130      640M   0.147585  50913280.0      300         1    53000    14   \n","41131      640M   0.134895  51859456.0      900        31  3145000    16   \n","41132      768M   0.203862  45862912.0      800        21  2001000     3   \n","41133     1024M   0.100398  59518976.0      900        11  5608000     5   \n","\n","       dayofweek  log_cpu_usage  log_ram_usage  log_num_req  log_conc_lvl  \n","0              3       0.081073      17.662550     4.615121      4.276666  \n","1              3       0.245213      17.839700     5.707110      3.091042  \n","2              3       0.300876      17.894900     6.552508      0.693147  \n","3              5       0.025892      17.591926     4.615121      3.737670  \n","4              3       0.102869      17.748286     6.685861      3.951244  \n","...          ...            ...            ...          ...           ...  \n","41129          4       0.156343      17.736664     6.803505      2.484907  \n","41130          4       0.137660      17.745634     5.707110      0.693147  \n","41131          2       0.126540      17.764048     6.803505      3.465736  \n","41132          3       0.185535      17.641167     6.685861      3.091042  \n","41133          0       0.095672      17.901806     6.803505      2.484907  \n","\n","[41134 rows x 16 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df_train"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["df_train.drop(columns=['timestamp'], inplace=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[],"source":["def extract_numeric_ram_limit(ram_limit):\n","    return float(ram_limit.replace('M', ''))"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["df_train['ram_limit_numeric'] = df_train['ram_limit'].apply(extract_numeric_ram_limit)\n","df_test['ram_limit_numeric'] = df_test['ram_limit'].apply(extract_numeric_ram_limit)"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["df_train.drop(columns=['ram_limit'], inplace=True)\n","df_test.drop(columns=['ram_limit'], inplace=True)"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 41134 entries, 0 to 41133\n","Data columns (total 15 columns):\n"," #   Column             Non-Null Count  Dtype  \n","---  ------             --------------  -----  \n"," 0   ID                 41134 non-null  int64  \n"," 1   cpu_type           41134 non-null  object \n"," 2   cpu_limit          41134 non-null  float64\n"," 3   cpu_usage          41134 non-null  float64\n"," 4   ram_usage          41134 non-null  float64\n"," 5   num_req            41134 non-null  int64  \n"," 6   conc_lvl           41134 non-null  int64  \n"," 7   latency            41134 non-null  int64  \n"," 8   hour               41134 non-null  int32  \n"," 9   dayofweek          41134 non-null  int32  \n"," 10  log_cpu_usage      41134 non-null  float64\n"," 11  log_ram_usage      41134 non-null  float64\n"," 12  log_num_req        41134 non-null  float64\n"," 13  log_conc_lvl       41134 non-null  float64\n"," 14  ram_limit_numeric  41134 non-null  float64\n","dtypes: float64(8), int32(2), int64(4), object(1)\n","memory usage: 4.4+ MB\n","None\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 17629 entries, 0 to 17628\n","Data columns (total 9 columns):\n"," #   Column             Non-Null Count  Dtype  \n","---  ------             --------------  -----  \n"," 0   ID                 17629 non-null  int64  \n"," 1   timestamp          17629 non-null  object \n"," 2   cpu_type           17629 non-null  object \n"," 3   cpu_limit          17629 non-null  float64\n"," 4   cpu_usage          17629 non-null  float64\n"," 5   ram_usage          17629 non-null  float64\n"," 6   num_req            17629 non-null  int64  \n"," 7   conc_lvl           17629 non-null  int64  \n"," 8   ram_limit_numeric  17629 non-null  float64\n","dtypes: float64(4), int64(3), object(2)\n","memory usage: 1.2+ MB\n","None\n"]}],"source":["print(df_train.info())\n","print(df_test.info())"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["df_train.drop(columns=['cpu_type'], inplace=True)\n","df_test.drop(columns=['cpu_type'], inplace=True)"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>cpu_limit</th>\n","      <th>cpu_usage</th>\n","      <th>ram_usage</th>\n","      <th>num_req</th>\n","      <th>conc_lvl</th>\n","      <th>latency</th>\n","      <th>hour</th>\n","      <th>dayofweek</th>\n","      <th>log_cpu_usage</th>\n","      <th>log_ram_usage</th>\n","      <th>log_num_req</th>\n","      <th>log_conc_lvl</th>\n","      <th>ram_limit_numeric</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2714</td>\n","      <td>2.0</td>\n","      <td>0.084450</td>\n","      <td>46854144.0</td>\n","      <td>100</td>\n","      <td>71</td>\n","      <td>7429000</td>\n","      <td>23</td>\n","      <td>3</td>\n","      <td>0.081073</td>\n","      <td>17.662550</td>\n","      <td>4.615121</td>\n","      <td>4.276666</td>\n","      <td>70.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>38113</td>\n","      <td>2.0</td>\n","      <td>0.277893</td>\n","      <td>55934976.0</td>\n","      <td>300</td>\n","      <td>21</td>\n","      <td>2196000</td>\n","      <td>23</td>\n","      <td>3</td>\n","      <td>0.245213</td>\n","      <td>17.839700</td>\n","      <td>5.707110</td>\n","      <td>3.091042</td>\n","      <td>70.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>33409</td>\n","      <td>2.5</td>\n","      <td>0.351042</td>\n","      <td>59109376.0</td>\n","      <td>700</td>\n","      <td>1</td>\n","      <td>37000</td>\n","      <td>13</td>\n","      <td>3</td>\n","      <td>0.300876</td>\n","      <td>17.894900</td>\n","      <td>6.552508</td>\n","      <td>0.693147</td>\n","      <td>66.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10123</td>\n","      <td>0.8</td>\n","      <td>0.026230</td>\n","      <td>43659264.0</td>\n","      <td>100</td>\n","      <td>41</td>\n","      <td>3946000</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>0.025892</td>\n","      <td>17.591926</td>\n","      <td>4.615121</td>\n","      <td>3.737670</td>\n","      <td>768.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>12815</td>\n","      <td>0.4</td>\n","      <td>0.108346</td>\n","      <td>51048448.0</td>\n","      <td>800</td>\n","      <td>51</td>\n","      <td>5084000</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>0.102869</td>\n","      <td>17.748286</td>\n","      <td>6.685861</td>\n","      <td>3.951244</td>\n","      <td>512.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>41129</th>\n","      <td>54343</td>\n","      <td>0.7</td>\n","      <td>0.169227</td>\n","      <td>50458624.0</td>\n","      <td>900</td>\n","      <td>11</td>\n","      <td>1039000</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>0.156343</td>\n","      <td>17.736664</td>\n","      <td>6.803505</td>\n","      <td>2.484907</td>\n","      <td>896.0</td>\n","    </tr>\n","    <tr>\n","      <th>41130</th>\n","      <td>38158</td>\n","      <td>1.5</td>\n","      <td>0.147585</td>\n","      <td>50913280.0</td>\n","      <td>300</td>\n","      <td>1</td>\n","      <td>53000</td>\n","      <td>14</td>\n","      <td>4</td>\n","      <td>0.137660</td>\n","      <td>17.745634</td>\n","      <td>5.707110</td>\n","      <td>0.693147</td>\n","      <td>640.0</td>\n","    </tr>\n","    <tr>\n","      <th>41131</th>\n","      <td>860</td>\n","      <td>1.8</td>\n","      <td>0.134895</td>\n","      <td>51859456.0</td>\n","      <td>900</td>\n","      <td>31</td>\n","      <td>3145000</td>\n","      <td>16</td>\n","      <td>2</td>\n","      <td>0.126540</td>\n","      <td>17.764048</td>\n","      <td>6.803505</td>\n","      <td>3.465736</td>\n","      <td>640.0</td>\n","    </tr>\n","    <tr>\n","      <th>41132</th>\n","      <td>15795</td>\n","      <td>0.7</td>\n","      <td>0.203862</td>\n","      <td>45862912.0</td>\n","      <td>800</td>\n","      <td>21</td>\n","      <td>2001000</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0.185535</td>\n","      <td>17.641167</td>\n","      <td>6.685861</td>\n","      <td>3.091042</td>\n","      <td>768.0</td>\n","    </tr>\n","    <tr>\n","      <th>41133</th>\n","      <td>56422</td>\n","      <td>0.1</td>\n","      <td>0.100398</td>\n","      <td>59518976.0</td>\n","      <td>900</td>\n","      <td>11</td>\n","      <td>5608000</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0.095672</td>\n","      <td>17.901806</td>\n","      <td>6.803505</td>\n","      <td>2.484907</td>\n","      <td>1024.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>41134 rows × 14 columns</p>\n","</div>"],"text/plain":["          ID  cpu_limit  cpu_usage   ram_usage  num_req  conc_lvl  latency  \\\n","0       2714        2.0   0.084450  46854144.0      100        71  7429000   \n","1      38113        2.0   0.277893  55934976.0      300        21  2196000   \n","2      33409        2.5   0.351042  59109376.0      700         1    37000   \n","3      10123        0.8   0.026230  43659264.0      100        41  3946000   \n","4      12815        0.4   0.108346  51048448.0      800        51  5084000   \n","...      ...        ...        ...         ...      ...       ...      ...   \n","41129  54343        0.7   0.169227  50458624.0      900        11  1039000   \n","41130  38158        1.5   0.147585  50913280.0      300         1    53000   \n","41131    860        1.8   0.134895  51859456.0      900        31  3145000   \n","41132  15795        0.7   0.203862  45862912.0      800        21  2001000   \n","41133  56422        0.1   0.100398  59518976.0      900        11  5608000   \n","\n","       hour  dayofweek  log_cpu_usage  log_ram_usage  log_num_req  \\\n","0        23          3       0.081073      17.662550     4.615121   \n","1        23          3       0.245213      17.839700     5.707110   \n","2        13          3       0.300876      17.894900     6.552508   \n","3         2          5       0.025892      17.591926     4.615121   \n","4         6          3       0.102869      17.748286     6.685861   \n","...     ...        ...            ...            ...          ...   \n","41129     2          4       0.156343      17.736664     6.803505   \n","41130    14          4       0.137660      17.745634     5.707110   \n","41131    16          2       0.126540      17.764048     6.803505   \n","41132     3          3       0.185535      17.641167     6.685861   \n","41133     5          0       0.095672      17.901806     6.803505   \n","\n","       log_conc_lvl  ram_limit_numeric  \n","0          4.276666               70.0  \n","1          3.091042               70.0  \n","2          0.693147               66.0  \n","3          3.737670              768.0  \n","4          3.951244              512.0  \n","...             ...                ...  \n","41129      2.484907              896.0  \n","41130      0.693147              640.0  \n","41131      3.465736              640.0  \n","41132      3.091042              768.0  \n","41133      2.484907             1024.0  \n","\n","[41134 rows x 14 columns]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df_train"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["(41134, 14)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["df_train.shape"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>cpu_limit</th>\n","      <th>cpu_usage</th>\n","      <th>ram_usage</th>\n","      <th>num_req</th>\n","      <th>conc_lvl</th>\n","      <th>latency</th>\n","      <th>hour</th>\n","      <th>dayofweek</th>\n","      <th>log_cpu_usage</th>\n","      <th>log_ram_usage</th>\n","      <th>log_num_req</th>\n","      <th>log_conc_lvl</th>\n","      <th>ram_limit_numeric</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2714</td>\n","      <td>2.0</td>\n","      <td>0.084450</td>\n","      <td>46854144.0</td>\n","      <td>100</td>\n","      <td>71</td>\n","      <td>7429000</td>\n","      <td>23</td>\n","      <td>3</td>\n","      <td>0.081073</td>\n","      <td>17.662550</td>\n","      <td>4.615121</td>\n","      <td>4.276666</td>\n","      <td>70.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>38113</td>\n","      <td>2.0</td>\n","      <td>0.277893</td>\n","      <td>55934976.0</td>\n","      <td>300</td>\n","      <td>21</td>\n","      <td>2196000</td>\n","      <td>23</td>\n","      <td>3</td>\n","      <td>0.245213</td>\n","      <td>17.839700</td>\n","      <td>5.707110</td>\n","      <td>3.091042</td>\n","      <td>70.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>33409</td>\n","      <td>2.5</td>\n","      <td>0.351042</td>\n","      <td>59109376.0</td>\n","      <td>700</td>\n","      <td>1</td>\n","      <td>37000</td>\n","      <td>13</td>\n","      <td>3</td>\n","      <td>0.300876</td>\n","      <td>17.894900</td>\n","      <td>6.552508</td>\n","      <td>0.693147</td>\n","      <td>66.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10123</td>\n","      <td>0.8</td>\n","      <td>0.026230</td>\n","      <td>43659264.0</td>\n","      <td>100</td>\n","      <td>41</td>\n","      <td>3946000</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>0.025892</td>\n","      <td>17.591926</td>\n","      <td>4.615121</td>\n","      <td>3.737670</td>\n","      <td>768.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>12815</td>\n","      <td>0.4</td>\n","      <td>0.108346</td>\n","      <td>51048448.0</td>\n","      <td>800</td>\n","      <td>51</td>\n","      <td>5084000</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>0.102869</td>\n","      <td>17.748286</td>\n","      <td>6.685861</td>\n","      <td>3.951244</td>\n","      <td>512.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>41129</th>\n","      <td>54343</td>\n","      <td>0.7</td>\n","      <td>0.169227</td>\n","      <td>50458624.0</td>\n","      <td>900</td>\n","      <td>11</td>\n","      <td>1039000</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>0.156343</td>\n","      <td>17.736664</td>\n","      <td>6.803505</td>\n","      <td>2.484907</td>\n","      <td>896.0</td>\n","    </tr>\n","    <tr>\n","      <th>41130</th>\n","      <td>38158</td>\n","      <td>1.5</td>\n","      <td>0.147585</td>\n","      <td>50913280.0</td>\n","      <td>300</td>\n","      <td>1</td>\n","      <td>53000</td>\n","      <td>14</td>\n","      <td>4</td>\n","      <td>0.137660</td>\n","      <td>17.745634</td>\n","      <td>5.707110</td>\n","      <td>0.693147</td>\n","      <td>640.0</td>\n","    </tr>\n","    <tr>\n","      <th>41131</th>\n","      <td>860</td>\n","      <td>1.8</td>\n","      <td>0.134895</td>\n","      <td>51859456.0</td>\n","      <td>900</td>\n","      <td>31</td>\n","      <td>3145000</td>\n","      <td>16</td>\n","      <td>2</td>\n","      <td>0.126540</td>\n","      <td>17.764048</td>\n","      <td>6.803505</td>\n","      <td>3.465736</td>\n","      <td>640.0</td>\n","    </tr>\n","    <tr>\n","      <th>41132</th>\n","      <td>15795</td>\n","      <td>0.7</td>\n","      <td>0.203862</td>\n","      <td>45862912.0</td>\n","      <td>800</td>\n","      <td>21</td>\n","      <td>2001000</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0.185535</td>\n","      <td>17.641167</td>\n","      <td>6.685861</td>\n","      <td>3.091042</td>\n","      <td>768.0</td>\n","    </tr>\n","    <tr>\n","      <th>41133</th>\n","      <td>56422</td>\n","      <td>0.1</td>\n","      <td>0.100398</td>\n","      <td>59518976.0</td>\n","      <td>900</td>\n","      <td>11</td>\n","      <td>5608000</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0.095672</td>\n","      <td>17.901806</td>\n","      <td>6.803505</td>\n","      <td>2.484907</td>\n","      <td>1024.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>41134 rows × 14 columns</p>\n","</div>"],"text/plain":["          ID  cpu_limit  cpu_usage   ram_usage  num_req  conc_lvl  latency  \\\n","0       2714        2.0   0.084450  46854144.0      100        71  7429000   \n","1      38113        2.0   0.277893  55934976.0      300        21  2196000   \n","2      33409        2.5   0.351042  59109376.0      700         1    37000   \n","3      10123        0.8   0.026230  43659264.0      100        41  3946000   \n","4      12815        0.4   0.108346  51048448.0      800        51  5084000   \n","...      ...        ...        ...         ...      ...       ...      ...   \n","41129  54343        0.7   0.169227  50458624.0      900        11  1039000   \n","41130  38158        1.5   0.147585  50913280.0      300         1    53000   \n","41131    860        1.8   0.134895  51859456.0      900        31  3145000   \n","41132  15795        0.7   0.203862  45862912.0      800        21  2001000   \n","41133  56422        0.1   0.100398  59518976.0      900        11  5608000   \n","\n","       hour  dayofweek  log_cpu_usage  log_ram_usage  log_num_req  \\\n","0        23          3       0.081073      17.662550     4.615121   \n","1        23          3       0.245213      17.839700     5.707110   \n","2        13          3       0.300876      17.894900     6.552508   \n","3         2          5       0.025892      17.591926     4.615121   \n","4         6          3       0.102869      17.748286     6.685861   \n","...     ...        ...            ...            ...          ...   \n","41129     2          4       0.156343      17.736664     6.803505   \n","41130    14          4       0.137660      17.745634     5.707110   \n","41131    16          2       0.126540      17.764048     6.803505   \n","41132     3          3       0.185535      17.641167     6.685861   \n","41133     5          0       0.095672      17.901806     6.803505   \n","\n","       log_conc_lvl  ram_limit_numeric  \n","0          4.276666               70.0  \n","1          3.091042               70.0  \n","2          0.693147               66.0  \n","3          3.737670              768.0  \n","4          3.951244              512.0  \n","...             ...                ...  \n","41129      2.484907              896.0  \n","41130      0.693147              640.0  \n","41131      3.465736              640.0  \n","41132      3.091042              768.0  \n","41133      2.484907             1024.0  \n","\n","[41134 rows x 14 columns]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["df_train"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[],"source":["X = df_train.drop(columns=['ID', 'latency'])\n","y = df_train['latency']"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["(41134, 12)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["X.describe()\n","X.shape"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[],"source":["X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n","from lightgbm import LGBMRegressor\n","from xgboost import XGBRegressor\n","from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n","from sklearn.metrics import r2_score\n","\n","pipeline_lgbm = Pipeline([\n","    ('poly_features', PolynomialFeatures(degree=2, include_bias=False)),\n","    ('scaler', StandardScaler()),\n","    ('lgbm', LGBMRegressor())\n","])\n","\n","pipeline_rf = Pipeline([\n","    ('poly_features', PolynomialFeatures(degree=2, include_bias=False)),\n","    ('scaler', StandardScaler()),\n","    ('rf', RandomForestRegressor())\n","])\n","\n","pipeline_xgb = Pipeline([\n","    ('poly_features', PolynomialFeatures(degree=2, include_bias=False)),\n","    ('scaler', StandardScaler()),\n","    ('xgb', XGBRegressor(subsample = 0.8, n_estimators = 225, max_depth = 7, learning_rate = 0.1, colsample_bytree = 0.8))\n","])\n","\n"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007323 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 16096\n","[LightGBM] [Info] Number of data points in the train set: 32907, number of used features: 90\n","[LightGBM] [Info] Start training from score 6489539.216337\n"]},{"data":{"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;poly_features&#x27;, PolynomialFeatures(include_bias=False)),\n","                (&#x27;scaler&#x27;, StandardScaler()),\n","                (&#x27;xgb&#x27;,\n","                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n","                              colsample_bylevel=None, colsample_bynode=None,\n","                              colsample_bytree=0.8, device=None,\n","                              early_stopping_rounds=None,\n","                              enable_categorical=False, eval_metric=None,\n","                              feature_types=None, gamma=None, grow_policy=None,\n","                              importance_type=None,\n","                              interaction_constraints=None, learning_rate=0.1,\n","                              max_bin=None, max_cat_threshold=None,\n","                              max_cat_to_onehot=None, max_delta_step=None,\n","                              max_depth=7, max_leaves=None,\n","                              min_child_weight=None, missing=nan,\n","                              monotone_constraints=None, multi_strategy=None,\n","                              n_estimators=225, n_jobs=None,\n","                              num_parallel_tree=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;poly_features&#x27;, PolynomialFeatures(include_bias=False)),\n","                (&#x27;scaler&#x27;, StandardScaler()),\n","                (&#x27;xgb&#x27;,\n","                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n","                              colsample_bylevel=None, colsample_bynode=None,\n","                              colsample_bytree=0.8, device=None,\n","                              early_stopping_rounds=None,\n","                              enable_categorical=False, eval_metric=None,\n","                              feature_types=None, gamma=None, grow_policy=None,\n","                              importance_type=None,\n","                              interaction_constraints=None, learning_rate=0.1,\n","                              max_bin=None, max_cat_threshold=None,\n","                              max_cat_to_onehot=None, max_delta_step=None,\n","                              max_depth=7, max_leaves=None,\n","                              min_child_weight=None, missing=nan,\n","                              monotone_constraints=None, multi_strategy=None,\n","                              n_estimators=225, n_jobs=None,\n","                              num_parallel_tree=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(include_bias=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n","             colsample_bylevel=None, colsample_bynode=None,\n","             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n","             enable_categorical=False, eval_metric=None, feature_types=None,\n","             gamma=None, grow_policy=None, importance_type=None,\n","             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n","             max_cat_threshold=None, max_cat_to_onehot=None,\n","             max_delta_step=None, max_depth=7, max_leaves=None,\n","             min_child_weight=None, missing=nan, monotone_constraints=None,\n","             multi_strategy=None, n_estimators=225, n_jobs=None,\n","             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div>"],"text/plain":["Pipeline(steps=[('poly_features', PolynomialFeatures(include_bias=False)),\n","                ('scaler', StandardScaler()),\n","                ('xgb',\n","                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n","                              colsample_bylevel=None, colsample_bynode=None,\n","                              colsample_bytree=0.8, device=None,\n","                              early_stopping_rounds=None,\n","                              enable_categorical=False, eval_metric=None,\n","                              feature_types=None, gamma=None, grow_policy=None,\n","                              importance_type=None,\n","                              interaction_constraints=None, learning_rate=0.1,\n","                              max_bin=None, max_cat_threshold=None,\n","                              max_cat_to_onehot=None, max_delta_step=None,\n","                              max_depth=7, max_leaves=None,\n","                              min_child_weight=None, missing=nan,\n","                              monotone_constraints=None, multi_strategy=None,\n","                              n_estimators=225, n_jobs=None,\n","                              num_parallel_tree=None, random_state=None, ...))])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["pipeline_lgbm.fit(X_train, y_train)\n","# pipeline_rf.fit(X_train, y_train)\n","pipeline_xgb.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":104,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'xgb__subsample': 0.8, 'xgb__n_estimators': 275, 'xgb__max_depth': 7, 'xgb__learning_rate': 0.05, 'xgb__colsample_bytree': 0.7}\n"]}],"source":["# Best Model from RandomizedSearchCV\n","# best_xgb_model = random_search.best_estimator_\n","# print(random_search.best_params_)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008619 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 16096\n","[LightGBM] [Info] Number of data points in the train set: 32907, number of used features: 90\n","[LightGBM] [Info] Start training from score 6489539.216337\n"]},{"data":{"text/html":["<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingRegressor(estimators=[(&#x27;lgbm&#x27;,\n","                             Pipeline(steps=[(&#x27;poly_features&#x27;,\n","                                              PolynomialFeatures(include_bias=False)),\n","                                             (&#x27;scaler&#x27;, StandardScaler()),\n","                                             (&#x27;lgbm&#x27;, LGBMRegressor())])),\n","                            (&#x27;xgb&#x27;,\n","                             Pipeline(steps=[(&#x27;poly_features&#x27;,\n","                                              PolynomialFeatures(include_bias=False)),\n","                                             (&#x27;scaler&#x27;, StandardScaler()),\n","                                             (&#x27;xgb&#x27;,\n","                                              XGBRegressor(base_score=None,\n","                                                           booster=None,\n","                                                           callbacks=None,\n","                                                           colsample_byl...\n","                                                           grow_policy=None,\n","                                                           importance_type=None,\n","                                                           interaction_constraints=None,\n","                                                           learning_rate=0.1,\n","                                                           max_bin=None,\n","                                                           max_cat_threshold=None,\n","                                                           max_cat_to_onehot=None,\n","                                                           max_delta_step=None,\n","                                                           max_depth=7,\n","                                                           max_leaves=None,\n","                                                           min_child_weight=None,\n","                                                           missing=nan,\n","                                                           monotone_constraints=None,\n","                                                           multi_strategy=None,\n","                                                           n_estimators=225,\n","                                                           n_jobs=None,\n","                                                           num_parallel_tree=None,\n","                                                           random_state=None, ...))]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingRegressor</label><div class=\"sk-toggleable__content\"><pre>VotingRegressor(estimators=[(&#x27;lgbm&#x27;,\n","                             Pipeline(steps=[(&#x27;poly_features&#x27;,\n","                                              PolynomialFeatures(include_bias=False)),\n","                                             (&#x27;scaler&#x27;, StandardScaler()),\n","                                             (&#x27;lgbm&#x27;, LGBMRegressor())])),\n","                            (&#x27;xgb&#x27;,\n","                             Pipeline(steps=[(&#x27;poly_features&#x27;,\n","                                              PolynomialFeatures(include_bias=False)),\n","                                             (&#x27;scaler&#x27;, StandardScaler()),\n","                                             (&#x27;xgb&#x27;,\n","                                              XGBRegressor(base_score=None,\n","                                                           booster=None,\n","                                                           callbacks=None,\n","                                                           colsample_byl...\n","                                                           grow_policy=None,\n","                                                           importance_type=None,\n","                                                           interaction_constraints=None,\n","                                                           learning_rate=0.1,\n","                                                           max_bin=None,\n","                                                           max_cat_threshold=None,\n","                                                           max_cat_to_onehot=None,\n","                                                           max_delta_step=None,\n","                                                           max_depth=7,\n","                                                           max_leaves=None,\n","                                                           min_child_weight=None,\n","                                                           missing=nan,\n","                                                           monotone_constraints=None,\n","                                                           multi_strategy=None,\n","                                                           n_estimators=225,\n","                                                           n_jobs=None,\n","                                                           num_parallel_tree=None,\n","                                                           random_state=None, ...))]))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(include_bias=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(include_bias=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n","             colsample_bylevel=None, colsample_bynode=None,\n","             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n","             enable_categorical=False, eval_metric=None, feature_types=None,\n","             gamma=None, grow_policy=None, importance_type=None,\n","             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n","             max_cat_threshold=None, max_cat_to_onehot=None,\n","             max_delta_step=None, max_depth=7, max_leaves=None,\n","             min_child_weight=None, missing=nan, monotone_constraints=None,\n","             multi_strategy=None, n_estimators=225, n_jobs=None,\n","             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"],"text/plain":["VotingRegressor(estimators=[('lgbm',\n","                             Pipeline(steps=[('poly_features',\n","                                              PolynomialFeatures(include_bias=False)),\n","                                             ('scaler', StandardScaler()),\n","                                             ('lgbm', LGBMRegressor())])),\n","                            ('xgb',\n","                             Pipeline(steps=[('poly_features',\n","                                              PolynomialFeatures(include_bias=False)),\n","                                             ('scaler', StandardScaler()),\n","                                             ('xgb',\n","                                              XGBRegressor(base_score=None,\n","                                                           booster=None,\n","                                                           callbacks=None,\n","                                                           colsample_byl...\n","                                                           grow_policy=None,\n","                                                           importance_type=None,\n","                                                           interaction_constraints=None,\n","                                                           learning_rate=0.1,\n","                                                           max_bin=None,\n","                                                           max_cat_threshold=None,\n","                                                           max_cat_to_onehot=None,\n","                                                           max_delta_step=None,\n","                                                           max_depth=7,\n","                                                           max_leaves=None,\n","                                                           min_child_weight=None,\n","                                                           missing=nan,\n","                                                           monotone_constraints=None,\n","                                                           multi_strategy=None,\n","                                                           n_estimators=225,\n","                                                           n_jobs=None,\n","                                                           num_parallel_tree=None,\n","                                                           random_state=None, ...))]))])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["voting_regressor = VotingRegressor([\n","    ('lgbm', pipeline_lgbm),\n","    # ('rf', pipeline_rf),\n","    ('xgb', pipeline_xgb)\n","])\n","\n","voting_regressor.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["R-squared (R²) on Validation Set with Best lgbm: 0.9692335745504258\n"]}],"source":["y_val_pred = voting_regressor.predict(X_val)\n","r2_xgb = r2_score(y_val, y_val_pred)\n","print(f'R-squared (R²) on Validation Set with Best lgbm: {r2_xgb}')"]},{"cell_type":"code","execution_count":112,"metadata":{"trusted":true},"outputs":[],"source":["# y_val_pred = model.predict(X_val)\n","# r2 = r2_score(y_val, y_val_pred)\n","# print(f'R-squared (R²) on Validation Set: {r2}')"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009179 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 16106\n","[LightGBM] [Info] Number of data points in the train set: 41134, number of used features: 90\n","[LightGBM] [Info] Start training from score 6483698.181553\n"]},{"data":{"text/html":["<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingRegressor(estimators=[(&#x27;lgbm&#x27;,\n","                             Pipeline(steps=[(&#x27;poly_features&#x27;,\n","                                              PolynomialFeatures(include_bias=False)),\n","                                             (&#x27;scaler&#x27;, StandardScaler()),\n","                                             (&#x27;lgbm&#x27;, LGBMRegressor())])),\n","                            (&#x27;xgb&#x27;,\n","                             Pipeline(steps=[(&#x27;poly_features&#x27;,\n","                                              PolynomialFeatures(include_bias=False)),\n","                                             (&#x27;scaler&#x27;, StandardScaler()),\n","                                             (&#x27;xgb&#x27;,\n","                                              XGBRegressor(base_score=None,\n","                                                           booster=None,\n","                                                           callbacks=None,\n","                                                           colsample_byl...\n","                                                           grow_policy=None,\n","                                                           importance_type=None,\n","                                                           interaction_constraints=None,\n","                                                           learning_rate=0.1,\n","                                                           max_bin=None,\n","                                                           max_cat_threshold=None,\n","                                                           max_cat_to_onehot=None,\n","                                                           max_delta_step=None,\n","                                                           max_depth=7,\n","                                                           max_leaves=None,\n","                                                           min_child_weight=None,\n","                                                           missing=nan,\n","                                                           monotone_constraints=None,\n","                                                           multi_strategy=None,\n","                                                           n_estimators=225,\n","                                                           n_jobs=None,\n","                                                           num_parallel_tree=None,\n","                                                           random_state=None, ...))]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingRegressor</label><div class=\"sk-toggleable__content\"><pre>VotingRegressor(estimators=[(&#x27;lgbm&#x27;,\n","                             Pipeline(steps=[(&#x27;poly_features&#x27;,\n","                                              PolynomialFeatures(include_bias=False)),\n","                                             (&#x27;scaler&#x27;, StandardScaler()),\n","                                             (&#x27;lgbm&#x27;, LGBMRegressor())])),\n","                            (&#x27;xgb&#x27;,\n","                             Pipeline(steps=[(&#x27;poly_features&#x27;,\n","                                              PolynomialFeatures(include_bias=False)),\n","                                             (&#x27;scaler&#x27;, StandardScaler()),\n","                                             (&#x27;xgb&#x27;,\n","                                              XGBRegressor(base_score=None,\n","                                                           booster=None,\n","                                                           callbacks=None,\n","                                                           colsample_byl...\n","                                                           grow_policy=None,\n","                                                           importance_type=None,\n","                                                           interaction_constraints=None,\n","                                                           learning_rate=0.1,\n","                                                           max_bin=None,\n","                                                           max_cat_threshold=None,\n","                                                           max_cat_to_onehot=None,\n","                                                           max_delta_step=None,\n","                                                           max_depth=7,\n","                                                           max_leaves=None,\n","                                                           min_child_weight=None,\n","                                                           missing=nan,\n","                                                           monotone_constraints=None,\n","                                                           multi_strategy=None,\n","                                                           n_estimators=225,\n","                                                           n_jobs=None,\n","                                                           num_parallel_tree=None,\n","                                                           random_state=None, ...))]))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(include_bias=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(include_bias=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n","             colsample_bylevel=None, colsample_bynode=None,\n","             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n","             enable_categorical=False, eval_metric=None, feature_types=None,\n","             gamma=None, grow_policy=None, importance_type=None,\n","             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n","             max_cat_threshold=None, max_cat_to_onehot=None,\n","             max_delta_step=None, max_depth=7, max_leaves=None,\n","             min_child_weight=None, missing=nan, monotone_constraints=None,\n","             multi_strategy=None, n_estimators=225, n_jobs=None,\n","             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"],"text/plain":["VotingRegressor(estimators=[('lgbm',\n","                             Pipeline(steps=[('poly_features',\n","                                              PolynomialFeatures(include_bias=False)),\n","                                             ('scaler', StandardScaler()),\n","                                             ('lgbm', LGBMRegressor())])),\n","                            ('xgb',\n","                             Pipeline(steps=[('poly_features',\n","                                              PolynomialFeatures(include_bias=False)),\n","                                             ('scaler', StandardScaler()),\n","                                             ('xgb',\n","                                              XGBRegressor(base_score=None,\n","                                                           booster=None,\n","                                                           callbacks=None,\n","                                                           colsample_byl...\n","                                                           grow_policy=None,\n","                                                           importance_type=None,\n","                                                           interaction_constraints=None,\n","                                                           learning_rate=0.1,\n","                                                           max_bin=None,\n","                                                           max_cat_threshold=None,\n","                                                           max_cat_to_onehot=None,\n","                                                           max_delta_step=None,\n","                                                           max_depth=7,\n","                                                           max_leaves=None,\n","                                                           min_child_weight=None,\n","                                                           missing=nan,\n","                                                           monotone_constraints=None,\n","                                                           multi_strategy=None,\n","                                                           n_estimators=225,\n","                                                           n_jobs=None,\n","                                                           num_parallel_tree=None,\n","                                                           random_state=None, ...))]))])"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["voting_regressor = VotingRegressor([\n","    ('lgbm', pipeline_lgbm),\n","    # ('rf', pipeline_rf),\n","    ('xgb', pipeline_xgb)\n","])\n","\n","voting_regressor.fit(X, y)"]},{"cell_type":"code","execution_count":33,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cpu_limit</th>\n","      <th>cpu_usage</th>\n","      <th>ram_usage</th>\n","      <th>num_req</th>\n","      <th>conc_lvl</th>\n","      <th>hour</th>\n","      <th>dayofweek</th>\n","      <th>log_cpu_usage</th>\n","      <th>log_ram_usage</th>\n","      <th>log_num_req</th>\n","      <th>log_conc_lvl</th>\n","      <th>ram_limit_numeric</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>38307</th>\n","      <td>0.1</td>\n","      <td>0.096577</td>\n","      <td>51159040.0</td>\n","      <td>100</td>\n","      <td>51</td>\n","      <td>14</td>\n","      <td>4</td>\n","      <td>0.092194</td>\n","      <td>17.750450</td>\n","      <td>4.615121</td>\n","      <td>3.951244</td>\n","      <td>1024.0</td>\n","    </tr>\n","    <tr>\n","      <th>22788</th>\n","      <td>0.6</td>\n","      <td>0.098265</td>\n","      <td>50835456.0</td>\n","      <td>1000</td>\n","      <td>41</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>0.093732</td>\n","      <td>17.744105</td>\n","      <td>6.908755</td>\n","      <td>3.737670</td>\n","      <td>256.0</td>\n","    </tr>\n","    <tr>\n","      <th>6010</th>\n","      <td>2.0</td>\n","      <td>0.560225</td>\n","      <td>58814464.0</td>\n","      <td>800</td>\n","      <td>11</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>0.444830</td>\n","      <td>17.889898</td>\n","      <td>6.685861</td>\n","      <td>2.484907</td>\n","      <td>66.0</td>\n","    </tr>\n","    <tr>\n","      <th>32313</th>\n","      <td>0.2</td>\n","      <td>0.193234</td>\n","      <td>63541248.0</td>\n","      <td>800</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0.176667</td>\n","      <td>17.967200</td>\n","      <td>6.685861</td>\n","      <td>2.484907</td>\n","      <td>512.0</td>\n","    </tr>\n","    <tr>\n","      <th>33689</th>\n","      <td>1.5</td>\n","      <td>0.000000</td>\n","      <td>35258368.0</td>\n","      <td>100</td>\n","      <td>11</td>\n","      <td>18</td>\n","      <td>3</td>\n","      <td>0.000000</td>\n","      <td>17.378213</td>\n","      <td>4.615121</td>\n","      <td>2.484907</td>\n","      <td>72.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6265</th>\n","      <td>0.2</td>\n","      <td>0.195358</td>\n","      <td>53153792.0</td>\n","      <td>600</td>\n","      <td>31</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>0.178446</td>\n","      <td>17.788700</td>\n","      <td>6.398595</td>\n","      <td>3.465736</td>\n","      <td>384.0</td>\n","    </tr>\n","    <tr>\n","      <th>11284</th>\n","      <td>1.1</td>\n","      <td>0.098054</td>\n","      <td>52637696.0</td>\n","      <td>800</td>\n","      <td>51</td>\n","      <td>23</td>\n","      <td>2</td>\n","      <td>0.093540</td>\n","      <td>17.778943</td>\n","      <td>6.685861</td>\n","      <td>3.951244</td>\n","      <td>896.0</td>\n","    </tr>\n","    <tr>\n","      <th>38158</th>\n","      <td>2.5</td>\n","      <td>0.233490</td>\n","      <td>48197632.0</td>\n","      <td>200</td>\n","      <td>51</td>\n","      <td>12</td>\n","      <td>3</td>\n","      <td>0.209848</td>\n","      <td>17.690820</td>\n","      <td>5.303305</td>\n","      <td>3.951244</td>\n","      <td>66.0</td>\n","    </tr>\n","    <tr>\n","      <th>860</th>\n","      <td>3.0</td>\n","      <td>0.370481</td>\n","      <td>58646528.0</td>\n","      <td>700</td>\n","      <td>61</td>\n","      <td>10</td>\n","      <td>6</td>\n","      <td>0.315162</td>\n","      <td>17.887039</td>\n","      <td>6.552508</td>\n","      <td>4.127134</td>\n","      <td>73.0</td>\n","    </tr>\n","    <tr>\n","      <th>15795</th>\n","      <td>3.5</td>\n","      <td>0.114357</td>\n","      <td>52670464.0</td>\n","      <td>100</td>\n","      <td>91</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>0.108278</td>\n","      <td>17.779565</td>\n","      <td>4.615121</td>\n","      <td>4.521789</td>\n","      <td>67.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>32907 rows × 12 columns</p>\n","</div>"],"text/plain":["       cpu_limit  cpu_usage   ram_usage  num_req  conc_lvl  hour  dayofweek  \\\n","38307        0.1   0.096577  51159040.0      100        51    14          4   \n","22788        0.6   0.098265  50835456.0     1000        41     4          3   \n","6010         2.0   0.560225  58814464.0      800        11     4          5   \n","32313        0.2   0.193234  63541248.0      800        11     3          0   \n","33689        1.5   0.000000  35258368.0      100        11    18          3   \n","...          ...        ...         ...      ...       ...   ...        ...   \n","6265         0.2   0.195358  53153792.0      600        31     7          4   \n","11284        1.1   0.098054  52637696.0      800        51    23          2   \n","38158        2.5   0.233490  48197632.0      200        51    12          3   \n","860          3.0   0.370481  58646528.0      700        61    10          6   \n","15795        3.5   0.114357  52670464.0      100        91    18          0   \n","\n","       log_cpu_usage  log_ram_usage  log_num_req  log_conc_lvl  \\\n","38307       0.092194      17.750450     4.615121      3.951244   \n","22788       0.093732      17.744105     6.908755      3.737670   \n","6010        0.444830      17.889898     6.685861      2.484907   \n","32313       0.176667      17.967200     6.685861      2.484907   \n","33689       0.000000      17.378213     4.615121      2.484907   \n","...              ...            ...          ...           ...   \n","6265        0.178446      17.788700     6.398595      3.465736   \n","11284       0.093540      17.778943     6.685861      3.951244   \n","38158       0.209848      17.690820     5.303305      3.951244   \n","860         0.315162      17.887039     6.552508      4.127134   \n","15795       0.108278      17.779565     4.615121      4.521789   \n","\n","       ram_limit_numeric  \n","38307             1024.0  \n","22788              256.0  \n","6010                66.0  \n","32313              512.0  \n","33689               72.0  \n","...                  ...  \n","6265               384.0  \n","11284              896.0  \n","38158               66.0  \n","860                 73.0  \n","15795               67.0  \n","\n","[32907 rows x 12 columns]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["X_train"]},{"cell_type":"code","execution_count":34,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>timestamp</th>\n","      <th>cpu_limit</th>\n","      <th>cpu_usage</th>\n","      <th>ram_usage</th>\n","      <th>num_req</th>\n","      <th>conc_lvl</th>\n","      <th>ram_limit_numeric</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1182</td>\n","      <td>2022-03-10 11:28:06</td>\n","      <td>0.1</td>\n","      <td>0.100592</td>\n","      <td>60809216.0</td>\n","      <td>900</td>\n","      <td>51</td>\n","      <td>1024.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>19002</td>\n","      <td>2022-03-11 02:33:23</td>\n","      <td>0.2</td>\n","      <td>0.202658</td>\n","      <td>64212992.0</td>\n","      <td>800</td>\n","      <td>71</td>\n","      <td>1024.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13933</td>\n","      <td>2022-03-06 11:38:14</td>\n","      <td>0.1</td>\n","      <td>0.100553</td>\n","      <td>68841472.0</td>\n","      <td>900</td>\n","      <td>41</td>\n","      <td>896.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10049</td>\n","      <td>2022-03-17 00:09:05</td>\n","      <td>1.0</td>\n","      <td>0.186460</td>\n","      <td>49979392.0</td>\n","      <td>700</td>\n","      <td>21</td>\n","      <td>896.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>19412</td>\n","      <td>2021-11-11 10:55:26</td>\n","      <td>2.5</td>\n","      <td>0.369512</td>\n","      <td>58982400.0</td>\n","      <td>1000</td>\n","      <td>81</td>\n","      <td>68.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17624</th>\n","      <td>741</td>\n","      <td>2021-11-13 20:13:24</td>\n","      <td>4.0</td>\n","      <td>0.713527</td>\n","      <td>62636032.0</td>\n","      <td>800</td>\n","      <td>11</td>\n","      <td>71.0</td>\n","    </tr>\n","    <tr>\n","      <th>17625</th>\n","      <td>36105</td>\n","      <td>2022-03-06 13:56:43</td>\n","      <td>0.1</td>\n","      <td>0.100533</td>\n","      <td>56094720.0</td>\n","      <td>700</td>\n","      <td>11</td>\n","      <td>896.0</td>\n","    </tr>\n","    <tr>\n","      <th>17626</th>\n","      <td>25313</td>\n","      <td>2022-03-19 02:01:13</td>\n","      <td>0.9</td>\n","      <td>0.197724</td>\n","      <td>48177152.0</td>\n","      <td>700</td>\n","      <td>21</td>\n","      <td>512.0</td>\n","    </tr>\n","    <tr>\n","      <th>17627</th>\n","      <td>25044</td>\n","      <td>2022-03-19 10:25:10</td>\n","      <td>0.2</td>\n","      <td>0.200379</td>\n","      <td>50946048.0</td>\n","      <td>800</td>\n","      <td>11</td>\n","      <td>128.0</td>\n","    </tr>\n","    <tr>\n","      <th>17628</th>\n","      <td>6947</td>\n","      <td>2022-03-11 00:22:15</td>\n","      <td>0.2</td>\n","      <td>0.201580</td>\n","      <td>67436544.0</td>\n","      <td>700</td>\n","      <td>71</td>\n","      <td>128.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17629 rows × 8 columns</p>\n","</div>"],"text/plain":["          ID            timestamp  cpu_limit  cpu_usage   ram_usage  num_req  \\\n","0       1182  2022-03-10 11:28:06        0.1   0.100592  60809216.0      900   \n","1      19002  2022-03-11 02:33:23        0.2   0.202658  64212992.0      800   \n","2      13933  2022-03-06 11:38:14        0.1   0.100553  68841472.0      900   \n","3      10049  2022-03-17 00:09:05        1.0   0.186460  49979392.0      700   \n","4      19412  2021-11-11 10:55:26        2.5   0.369512  58982400.0     1000   \n","...      ...                  ...        ...        ...         ...      ...   \n","17624    741  2021-11-13 20:13:24        4.0   0.713527  62636032.0      800   \n","17625  36105  2022-03-06 13:56:43        0.1   0.100533  56094720.0      700   \n","17626  25313  2022-03-19 02:01:13        0.9   0.197724  48177152.0      700   \n","17627  25044  2022-03-19 10:25:10        0.2   0.200379  50946048.0      800   \n","17628   6947  2022-03-11 00:22:15        0.2   0.201580  67436544.0      700   \n","\n","       conc_lvl  ram_limit_numeric  \n","0            51             1024.0  \n","1            71             1024.0  \n","2            41              896.0  \n","3            21              896.0  \n","4            81               68.0  \n","...         ...                ...  \n","17624        11               71.0  \n","17625        11              896.0  \n","17626        21              512.0  \n","17627        11              128.0  \n","17628        71              128.0  \n","\n","[17629 rows x 8 columns]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["df_test"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["df_test['timestamp'] = pd.to_datetime(df_test['timestamp'])\n","df_test['hour'] = df_test['timestamp'].dt.hour\n","df_test['day'] = df_test['timestamp'].dt.day\n","df_test['month'] = df_test['timestamp'].dt.month\n","df_test['dayofweek'] = df_test['timestamp'].dt.dayofweek\n","\n","df_test.drop(columns=['timestamp'], inplace=True)"]},{"cell_type":"code","execution_count":36,"metadata":{"trusted":true},"outputs":[],"source":["df_test['log_cpu_usage'] = np.log1p(df_test['cpu_usage'])\n","df_test['log_ram_usage'] = np.log1p(df_test['ram_usage'])\n","df_test['log_num_req'] = np.log1p(df_test['num_req'])\n","df_test['log_conc_lvl'] = np.log1p(df_test['conc_lvl'])"]},{"cell_type":"code","execution_count":37,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>cpu_limit</th>\n","      <th>cpu_usage</th>\n","      <th>ram_usage</th>\n","      <th>num_req</th>\n","      <th>conc_lvl</th>\n","      <th>ram_limit_numeric</th>\n","      <th>hour</th>\n","      <th>day</th>\n","      <th>month</th>\n","      <th>dayofweek</th>\n","      <th>log_cpu_usage</th>\n","      <th>log_ram_usage</th>\n","      <th>log_num_req</th>\n","      <th>log_conc_lvl</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1182</td>\n","      <td>0.1</td>\n","      <td>0.100592</td>\n","      <td>60809216.0</td>\n","      <td>900</td>\n","      <td>51</td>\n","      <td>1024.0</td>\n","      <td>11</td>\n","      <td>10</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0.095848</td>\n","      <td>17.923252</td>\n","      <td>6.803505</td>\n","      <td>3.951244</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>19002</td>\n","      <td>0.2</td>\n","      <td>0.202658</td>\n","      <td>64212992.0</td>\n","      <td>800</td>\n","      <td>71</td>\n","      <td>1024.0</td>\n","      <td>2</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.184534</td>\n","      <td>17.977716</td>\n","      <td>6.685861</td>\n","      <td>4.276666</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13933</td>\n","      <td>0.1</td>\n","      <td>0.100553</td>\n","      <td>68841472.0</td>\n","      <td>900</td>\n","      <td>41</td>\n","      <td>896.0</td>\n","      <td>11</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>0.095813</td>\n","      <td>18.047317</td>\n","      <td>6.803505</td>\n","      <td>3.737670</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10049</td>\n","      <td>1.0</td>\n","      <td>0.186460</td>\n","      <td>49979392.0</td>\n","      <td>700</td>\n","      <td>21</td>\n","      <td>896.0</td>\n","      <td>0</td>\n","      <td>17</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0.170974</td>\n","      <td>17.727121</td>\n","      <td>6.552508</td>\n","      <td>3.091042</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>19412</td>\n","      <td>2.5</td>\n","      <td>0.369512</td>\n","      <td>58982400.0</td>\n","      <td>1000</td>\n","      <td>81</td>\n","      <td>68.0</td>\n","      <td>10</td>\n","      <td>11</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>0.314454</td>\n","      <td>17.892750</td>\n","      <td>6.908755</td>\n","      <td>4.406719</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17624</th>\n","      <td>741</td>\n","      <td>4.0</td>\n","      <td>0.713527</td>\n","      <td>62636032.0</td>\n","      <td>800</td>\n","      <td>11</td>\n","      <td>71.0</td>\n","      <td>20</td>\n","      <td>13</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>0.538554</td>\n","      <td>17.952851</td>\n","      <td>6.685861</td>\n","      <td>2.484907</td>\n","    </tr>\n","    <tr>\n","      <th>17625</th>\n","      <td>36105</td>\n","      <td>0.1</td>\n","      <td>0.100533</td>\n","      <td>56094720.0</td>\n","      <td>700</td>\n","      <td>11</td>\n","      <td>896.0</td>\n","      <td>13</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>0.095795</td>\n","      <td>17.842552</td>\n","      <td>6.552508</td>\n","      <td>2.484907</td>\n","    </tr>\n","    <tr>\n","      <th>17626</th>\n","      <td>25313</td>\n","      <td>0.9</td>\n","      <td>0.197724</td>\n","      <td>48177152.0</td>\n","      <td>700</td>\n","      <td>21</td>\n","      <td>512.0</td>\n","      <td>2</td>\n","      <td>19</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>0.180423</td>\n","      <td>17.690395</td>\n","      <td>6.552508</td>\n","      <td>3.091042</td>\n","    </tr>\n","    <tr>\n","      <th>17627</th>\n","      <td>25044</td>\n","      <td>0.2</td>\n","      <td>0.200379</td>\n","      <td>50946048.0</td>\n","      <td>800</td>\n","      <td>11</td>\n","      <td>128.0</td>\n","      <td>10</td>\n","      <td>19</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>0.182637</td>\n","      <td>17.746278</td>\n","      <td>6.685861</td>\n","      <td>2.484907</td>\n","    </tr>\n","    <tr>\n","      <th>17628</th>\n","      <td>6947</td>\n","      <td>0.2</td>\n","      <td>0.201580</td>\n","      <td>67436544.0</td>\n","      <td>700</td>\n","      <td>71</td>\n","      <td>128.0</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.183637</td>\n","      <td>18.026698</td>\n","      <td>6.552508</td>\n","      <td>4.276666</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17629 rows × 15 columns</p>\n","</div>"],"text/plain":["          ID  cpu_limit  cpu_usage   ram_usage  num_req  conc_lvl  \\\n","0       1182        0.1   0.100592  60809216.0      900        51   \n","1      19002        0.2   0.202658  64212992.0      800        71   \n","2      13933        0.1   0.100553  68841472.0      900        41   \n","3      10049        1.0   0.186460  49979392.0      700        21   \n","4      19412        2.5   0.369512  58982400.0     1000        81   \n","...      ...        ...        ...         ...      ...       ...   \n","17624    741        4.0   0.713527  62636032.0      800        11   \n","17625  36105        0.1   0.100533  56094720.0      700        11   \n","17626  25313        0.9   0.197724  48177152.0      700        21   \n","17627  25044        0.2   0.200379  50946048.0      800        11   \n","17628   6947        0.2   0.201580  67436544.0      700        71   \n","\n","       ram_limit_numeric  hour  day  month  dayofweek  log_cpu_usage  \\\n","0                 1024.0    11   10      3          3       0.095848   \n","1                 1024.0     2   11      3          4       0.184534   \n","2                  896.0    11    6      3          6       0.095813   \n","3                  896.0     0   17      3          3       0.170974   \n","4                   68.0    10   11     11          3       0.314454   \n","...                  ...   ...  ...    ...        ...            ...   \n","17624               71.0    20   13     11          5       0.538554   \n","17625              896.0    13    6      3          6       0.095795   \n","17626              512.0     2   19      3          5       0.180423   \n","17627              128.0    10   19      3          5       0.182637   \n","17628              128.0     0   11      3          4       0.183637   \n","\n","       log_ram_usage  log_num_req  log_conc_lvl  \n","0          17.923252     6.803505      3.951244  \n","1          17.977716     6.685861      4.276666  \n","2          18.047317     6.803505      3.737670  \n","3          17.727121     6.552508      3.091042  \n","4          17.892750     6.908755      4.406719  \n","...              ...          ...           ...  \n","17624      17.952851     6.685861      2.484907  \n","17625      17.842552     6.552508      2.484907  \n","17626      17.690395     6.552508      3.091042  \n","17627      17.746278     6.685861      2.484907  \n","17628      18.026698     6.552508      4.276666  \n","\n","[17629 rows x 15 columns]"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["df_test"]},{"cell_type":"code","execution_count":38,"metadata":{"trusted":true},"outputs":[],"source":["df_test = df_test.set_index('ID')\n","missing_cols = set(X_train.columns) - set(df_test.columns)\n","for col in missing_cols:\n","    df_test[col] = 0\n","df_test = df_test.reset_index()\n","X_test = df_test[X_train.columns]"]},{"cell_type":"code","execution_count":39,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["(17629, 12)"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["X_test.shape"]},{"cell_type":"code","execution_count":41,"metadata":{"trusted":true},"outputs":[],"source":["y_test_pred = voting_regressor.predict(X_test)"]},{"cell_type":"code","execution_count":43,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>cpu_limit</th>\n","      <th>cpu_usage</th>\n","      <th>ram_usage</th>\n","      <th>num_req</th>\n","      <th>conc_lvl</th>\n","      <th>ram_limit_numeric</th>\n","      <th>hour</th>\n","      <th>day</th>\n","      <th>month</th>\n","      <th>dayofweek</th>\n","      <th>log_cpu_usage</th>\n","      <th>log_ram_usage</th>\n","      <th>log_num_req</th>\n","      <th>log_conc_lvl</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1182</td>\n","      <td>0.1</td>\n","      <td>0.100592</td>\n","      <td>60809216.0</td>\n","      <td>900</td>\n","      <td>51</td>\n","      <td>1024.0</td>\n","      <td>11</td>\n","      <td>10</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0.095848</td>\n","      <td>17.923252</td>\n","      <td>6.803505</td>\n","      <td>3.951244</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>19002</td>\n","      <td>0.2</td>\n","      <td>0.202658</td>\n","      <td>64212992.0</td>\n","      <td>800</td>\n","      <td>71</td>\n","      <td>1024.0</td>\n","      <td>2</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.184534</td>\n","      <td>17.977716</td>\n","      <td>6.685861</td>\n","      <td>4.276666</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13933</td>\n","      <td>0.1</td>\n","      <td>0.100553</td>\n","      <td>68841472.0</td>\n","      <td>900</td>\n","      <td>41</td>\n","      <td>896.0</td>\n","      <td>11</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>0.095813</td>\n","      <td>18.047317</td>\n","      <td>6.803505</td>\n","      <td>3.737670</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10049</td>\n","      <td>1.0</td>\n","      <td>0.186460</td>\n","      <td>49979392.0</td>\n","      <td>700</td>\n","      <td>21</td>\n","      <td>896.0</td>\n","      <td>0</td>\n","      <td>17</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0.170974</td>\n","      <td>17.727121</td>\n","      <td>6.552508</td>\n","      <td>3.091042</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>19412</td>\n","      <td>2.5</td>\n","      <td>0.369512</td>\n","      <td>58982400.0</td>\n","      <td>1000</td>\n","      <td>81</td>\n","      <td>68.0</td>\n","      <td>10</td>\n","      <td>11</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>0.314454</td>\n","      <td>17.892750</td>\n","      <td>6.908755</td>\n","      <td>4.406719</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17624</th>\n","      <td>741</td>\n","      <td>4.0</td>\n","      <td>0.713527</td>\n","      <td>62636032.0</td>\n","      <td>800</td>\n","      <td>11</td>\n","      <td>71.0</td>\n","      <td>20</td>\n","      <td>13</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>0.538554</td>\n","      <td>17.952851</td>\n","      <td>6.685861</td>\n","      <td>2.484907</td>\n","    </tr>\n","    <tr>\n","      <th>17625</th>\n","      <td>36105</td>\n","      <td>0.1</td>\n","      <td>0.100533</td>\n","      <td>56094720.0</td>\n","      <td>700</td>\n","      <td>11</td>\n","      <td>896.0</td>\n","      <td>13</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>0.095795</td>\n","      <td>17.842552</td>\n","      <td>6.552508</td>\n","      <td>2.484907</td>\n","    </tr>\n","    <tr>\n","      <th>17626</th>\n","      <td>25313</td>\n","      <td>0.9</td>\n","      <td>0.197724</td>\n","      <td>48177152.0</td>\n","      <td>700</td>\n","      <td>21</td>\n","      <td>512.0</td>\n","      <td>2</td>\n","      <td>19</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>0.180423</td>\n","      <td>17.690395</td>\n","      <td>6.552508</td>\n","      <td>3.091042</td>\n","    </tr>\n","    <tr>\n","      <th>17627</th>\n","      <td>25044</td>\n","      <td>0.2</td>\n","      <td>0.200379</td>\n","      <td>50946048.0</td>\n","      <td>800</td>\n","      <td>11</td>\n","      <td>128.0</td>\n","      <td>10</td>\n","      <td>19</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>0.182637</td>\n","      <td>17.746278</td>\n","      <td>6.685861</td>\n","      <td>2.484907</td>\n","    </tr>\n","    <tr>\n","      <th>17628</th>\n","      <td>6947</td>\n","      <td>0.2</td>\n","      <td>0.201580</td>\n","      <td>67436544.0</td>\n","      <td>700</td>\n","      <td>71</td>\n","      <td>128.0</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0.183637</td>\n","      <td>18.026698</td>\n","      <td>6.552508</td>\n","      <td>4.276666</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17629 rows × 15 columns</p>\n","</div>"],"text/plain":["          ID  cpu_limit  cpu_usage   ram_usage  num_req  conc_lvl  \\\n","0       1182        0.1   0.100592  60809216.0      900        51   \n","1      19002        0.2   0.202658  64212992.0      800        71   \n","2      13933        0.1   0.100553  68841472.0      900        41   \n","3      10049        1.0   0.186460  49979392.0      700        21   \n","4      19412        2.5   0.369512  58982400.0     1000        81   \n","...      ...        ...        ...         ...      ...       ...   \n","17624    741        4.0   0.713527  62636032.0      800        11   \n","17625  36105        0.1   0.100533  56094720.0      700        11   \n","17626  25313        0.9   0.197724  48177152.0      700        21   \n","17627  25044        0.2   0.200379  50946048.0      800        11   \n","17628   6947        0.2   0.201580  67436544.0      700        71   \n","\n","       ram_limit_numeric  hour  day  month  dayofweek  log_cpu_usage  \\\n","0                 1024.0    11   10      3          3       0.095848   \n","1                 1024.0     2   11      3          4       0.184534   \n","2                  896.0    11    6      3          6       0.095813   \n","3                  896.0     0   17      3          3       0.170974   \n","4                   68.0    10   11     11          3       0.314454   \n","...                  ...   ...  ...    ...        ...            ...   \n","17624               71.0    20   13     11          5       0.538554   \n","17625              896.0    13    6      3          6       0.095795   \n","17626              512.0     2   19      3          5       0.180423   \n","17627              128.0    10   19      3          5       0.182637   \n","17628              128.0     0   11      3          4       0.183637   \n","\n","       log_ram_usage  log_num_req  log_conc_lvl  \n","0          17.923252     6.803505      3.951244  \n","1          17.977716     6.685861      4.276666  \n","2          18.047317     6.803505      3.737670  \n","3          17.727121     6.552508      3.091042  \n","4          17.892750     6.908755      4.406719  \n","...              ...          ...           ...  \n","17624      17.952851     6.685861      2.484907  \n","17625      17.842552     6.552508      2.484907  \n","17626      17.690395     6.552508      3.091042  \n","17627      17.746278     6.685861      2.484907  \n","17628      18.026698     6.552508      4.276666  \n","\n","[17629 rows x 15 columns]"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["df_test"]},{"cell_type":"code","execution_count":44,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["      ID       latency\n","0   1182  1.095707e+08\n","1  19002  6.117965e+07\n","2  13933  1.934923e+07\n","3  10049  2.054799e+06\n","4  19412  7.764894e+06\n"]}],"source":["submission = pd.DataFrame({'ID': df_test['ID'], 'latency': y_test_pred})\n","submission.to_csv('submission_voting_2.csv', index=False)\n","\n","print(submission.head())"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5300373,"sourceId":8811748,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
